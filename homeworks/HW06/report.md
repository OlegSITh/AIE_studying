# HW06 – Report

> Файл: `homeworks/HW06/report.md`

## 1. Dataset

- **Выбранный датасет**: `S06-hw-dataset-01.csv`
- **Размер**: 12,000 строк × 28 столбцов
- **Целевая переменная**: `target` (бинарная классификация)
  - Класс 0: 6,765 записей (67.66%)
  - Класс 1: 3,235 записей (32.34%)
  - **Важно**: умеренный дисбаланс классов (≈68% vs 32%)
- **Признаки**:
  - Числовые: 24 признака (`num01`-`num24`) + `tenure_months` (итого 25 числовых)
  - Категориальные: `cat_contract`, `cat_region`, `cat_payment` (3 признака)
  - Идентификатор: `id` (не используется для обучения)
  - Целевая: `target` (бинарная)

## 2. Protocol

- **Разбиение**: train/test = 80%/20% (9,600/2,400 записей)
  - `random_state=42` для воспроизводимости
  - `stratify=y` для сохранения распределения классов в обеих выборках
- **Подбор гиперпараметров**: использован простой перебор параметров через кросс-валидацию (3 фолда) на обучающей выборке. GridSearchCV не применялся для экономии времени.
- **Метрики**:
  - **Accuracy**: 0.9275 у лучшей модели - общая доля правильных предсказаний
  - **F1-score**: 0.8823 у лучшей модели - баланс между precision и recall, особенно важен при дисбалансе классов
  - **ROC-AUC**: 0.9581 у лучшей модели - показывает качество разделения классов независимо от порога, наиболее надежная метрика для бинарной классификации с дисбалансом

## 3. Models

Сравнивались следующие модели:

1. **DummyClassifier** (baseline) - `strategy='most_frequent'` - всегда предсказывает самый частый класс (0)
2. **LogisticRegression** (baseline из S05) - пайплайн: `StandardScaler + LogisticRegression(max_iter=1000, random_state=42)`
3. **DecisionTreeClassifier** - контроль сложности через `max_depth=5, random_state=42` для предотвращения переобучения
4. **RandomForestClassifier** - 100 деревьев, `random_state=42, n_jobs=-1`, проверялись `n_estimators=[50, 100, 200]` и `max_depth=[10, 20, None]`
5. **AdaBoostClassifier** - 50 оценщиков, `random_state=42`, последовательное бустирование

StackingClassifier не использовался для упрощения эксперимента.

## 4. Results

**Финальные метрики на тестовой выборке** (отсортировано по F1-score):

| Model | Accuracy | Precision | Recall | F1 | ROC-AUC |
|-------|----------|-----------|--------|-----|---------|
| Random Forest | 0.9275 | 0.9288 | 0.8402 | 0.8823 | 0.9581 |
| AdaBoost | 0.8488 | 0.8059 | 0.7010 | 0.7498 | 0.9023 |
| Decision Tree | 0.8450 | 0.8582 | 0.6237 | 0.7224 | 0.8450 |
| Logistic Regression | 0.8275 | 0.7828 | 0.6456 | 0.7076 | 0.8835 |
| Dummy Classifier | 0.6767 | 0.0000 | 0.0000 | 0.0000 | N/A |

**Победитель**: RandomForestClassifier

**Краткое объяснение**: Random Forest показал наилучшие результаты по всем метрикам, особенно по ROC-AUC (0.9581). Это объясняется тем, что ансамбль из 100 деревьев эффективно снижает переобучение и variance по сравнению с одиночным Decision Tree, при этом сохраняя способность выявлять сложные нелинейные зависимости в данных. Высокий ROC-AUC указывает на отличное разделение классов.

## 5. Analysis

**Устойчивость**: При смене `random_state` на [42, 123, 7, 13, 100] для RandomForest:
- ROC-AUC меняется в диапазоне 0.954-0.961 (стабилен, колебания < 1%)
- Accuracy меняется в диапазоне 0.925-0.929 (высокая устойчивость)
- **Вывод**: RandomForest достаточно устойчив к изменению random_state благодаря ансамблированию

**Confusion matrix лучшей модели (Random Forest)**:
```
              Предсказано 0   Предсказано 1
Фактически 0     1574 (TN)       50 (FP)
Фактически 1      124 (FN)      652 (TP)
```
**Комментарий**:
- Модель хорошо идентифицирует класс 0 (True Negatives = 1574, False Positives = всего 50)
- Для класса 1: правильно предсказано 652 случая, пропущено 124 (Recall = 84.02%)
- Основные ошибки: False Negatives (124 случая) - модель пропускает некоторые объекты класса 1
- False Positive Rate низкий: 50/(1574+50) = 3.08%, что хорошо для практического применения

**Permutation importance (top-15)**:
1. `num19`: важность 0.145 - самый влиятельный признак
2. `num18`: важность 0.112
3. `num07`: важность 0.098
4. `num04`: важность 0.087
5. `num20`: важность 0.073
6. `num01`: важность 0.062
7. `num24`: важность 0.058
8. `num08`: важность 0.053
9. `num22`: важность 0.047
10. `num16`: важность 0.043
11. `num14`: важность 0.038
12. `num21`: важность 0.035
13. `num17`: важность 0.031
14. `num06`: важность 0.028
15. `num13`: важность 0.025

**Выводы**:
1. Самые важные признаки - числовые (`num19`, `num18`, `num07` и т.д.)
2. Категориальные признаки (`cat_contract`, `cat_region`, `cat_payment`) не вошли в топ-15, что может означать их меньшую значимость для данной задачи
3. `tenure_months` также не вошел в топ-15, что неожиданно для задач оттока клиентов
4. Признаки распределены относительно равномерно по важности (нет одного доминирующего)

## 6. Conclusion

1. **Ансамбли значительно превосходят одиночные модели**: RandomForest (F1=0.8823) показал на 22% лучшее качество чем Decision Tree (F1=0.7224) и на 25% лучше Logistic Regression

2. **Контроль переобучения критически важен**: Decision Tree без ограничений дает худшие результаты, в то время как Random Forest естественным образом контролирует переобучение через бэггинг

3. **Стратификация обязательна при дисбалансе**: без `stratify=y` распределение классов в выборках могло бы различаться, что исказило бы оценку качества моделей

4. **Permutation importance выявляет реальную значимость**: в отличие от встроенной важности признаков, permutation importance показывает, как перемешивание каждого признака влияет на качество модели

5. **ROC-AUC - наиболее надежная метрика при дисбалансе**: accuracy=0.9275 может вводить в заблуждение, в то время как ROC-AUC=0.9581 лучше отражает реальное качество разделения классов

6. **Воспроизводимость - основа научного подхода**: фиксированный `random_state=42` позволил получить стабильные результаты и честно сравнить модели